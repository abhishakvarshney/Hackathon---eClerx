{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hackathon.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMi76gLIc6ulpp1Eykcp/iU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishakvarshney/Hackathon---eClerx/blob/master/Hackathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS27rMuGTfCh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "a4b61c27-9ac7-448b-a422-63a2194d3ffc"
      },
      "source": [
        "def download_data():\n",
        "    !wget 'https://storage.googleapis.com/kaggle-data-sets/4133%2F8841%2Fbundle%2Farchive.zip?GoogleAccessId=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com&Expires=1595929231&Signature=M2UzMApcy0Epe55p0OUB9uwn%2FQo0bWS09xzwITl0ctga0%2F7i%2FqAR%2BZcSOXvv%2F0EjECpRdu5%2FWiN89I9F25sg8u4bqQaC29bXUmxFoopThJscoFq5SinQzOSEIvLWNup2cEU94%2F%2BENpzDCvOYIJ2tE9yWv97HsGLf9qJFNqbsMsolIwfJZmqzXhqY%2FRmsPgjJ%2F3eG0AjF1HyNKIwRmyN3INMAhZbovEEKCSlTjmHg1L%2Bx8YuofBZXmLIOCYDDkPEv2jqP%2FTI6%2FPUQIznSvBZTRxR3e2LMyduHwSViUGUfLf59z0VvVcQaYDvGXFzJR%2F21h6PL%2BM3cO401dP6VuCG7kg%3D%3D' -O \"data.zip\"\n",
        "    !unzip -o \"data.zip\"\n",
        "    !rm -rf \"data.zip\"\n",
        "download_data()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-25 20:52:51--  https://storage.googleapis.com/kaggle-data-sets/4133%2F8841%2Fbundle%2Farchive.zip?GoogleAccessId=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com&Expires=1595929231&Signature=M2UzMApcy0Epe55p0OUB9uwn%2FQo0bWS09xzwITl0ctga0%2F7i%2FqAR%2BZcSOXvv%2F0EjECpRdu5%2FWiN89I9F25sg8u4bqQaC29bXUmxFoopThJscoFq5SinQzOSEIvLWNup2cEU94%2F%2BENpzDCvOYIJ2tE9yWv97HsGLf9qJFNqbsMsolIwfJZmqzXhqY%2FRmsPgjJ%2F3eG0AjF1HyNKIwRmyN3INMAhZbovEEKCSlTjmHg1L%2Bx8YuofBZXmLIOCYDDkPEv2jqP%2FTI6%2FPUQIznSvBZTRxR3e2LMyduHwSViUGUfLf59z0VvVcQaYDvGXFzJR%2F21h6PL%2BM3cO401dP6VuCG7kg%3D%3D\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.194.128, 172.253.118.128, 74.125.24.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.194.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 176772673 (169M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "\rdata.zip              0%[                    ]       0  --.-KB/s               \rdata.zip             18%[==>                 ]  32.01M  65.1MB/s               \rdata.zip             54%[=========>          ]  91.41M   132MB/s               \rdata.zip             85%[================>   ] 144.01M   156MB/s               \rdata.zip            100%[===================>] 168.58M   168MB/s    in 1.0s    \n",
            "\n",
            "2020-07-25 20:52:53 (168 MB/s) - ‘data.zip’ saved [176772673/176772673]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-4d3e317e2522>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unzip -o \"data.zip\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm -rf \"data.zip\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdownload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-79-4d3e317e2522>\u001b[0m in \u001b[0;36mdownload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdownload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget \\'https://storage.googleapis.com/kaggle-data-sets/4133%2F8841%2Fbundle%2Farchive.zip?GoogleAccessId=gcp-kaggle-com@kaggle-161607.iam.gserviceaccount.com&Expires=1595929231&Signature=M2UzMApcy0Epe55p0OUB9uwn%2FQo0bWS09xzwITl0ctga0%2F7i%2FqAR%2BZcSOXvv%2F0EjECpRdu5%2FWiN89I9F25sg8u4bqQaC29bXUmxFoopThJscoFq5SinQzOSEIvLWNup2cEU94%2F%2BENpzDCvOYIJ2tE9yWv97HsGLf9qJFNqbsMsolIwfJZmqzXhqY%2FRmsPgjJ%2F3eG0AjF1HyNKIwRmyN3INMAhZbovEEKCSlTjmHg1L%2Bx8YuofBZXmLIOCYDDkPEv2jqP%2FTI6%2FPUQIznSvBZTRxR3e2LMyduHwSViUGUfLf59z0VvVcQaYDvGXFzJR%2F21h6PL%2BM3cO401dP6VuCG7kg%3D%3D\\' -O \"data.zip\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unzip -o \"data.zip\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm -rf \"data.zip\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdownload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0mhide_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_remove_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhide_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1hkkBnMGV0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install scattertext spacy_cld spacymoji empath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYCC3tdHUcs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# library imports\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "matplotlib.style.use('ggplot')\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "width = 0.75\n",
        "plt.rcParams['xtick.labelsize'] = 15\n",
        "plt.rcParams['ytick.labelsize'] = 15\n",
        "plt.rcParams[\"font.weight\"] = \"bold\"\n",
        "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
        "plt.axis('off')\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "import scattertext as st\n",
        "import spacy\n",
        "import spacy_cld\n",
        "\n",
        "from IPython.display import IFrame\n",
        "from IPython.core.display import display, HTML\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "from tqdm.notebook import tqdm as tqdm  # cool progress bars\n",
        "tqdm().pandas()  # Enable tracking of progress in dataframe `apply` calls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POxWuNa5DUSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 8192 - large enough for demonstration, larger values make network training slower\n",
        "MAX_VOCAB_SIZE = 2**13\n",
        "# seq2seq generally relies on fixed length message vectors - longer messages provide more info\n",
        "# but result in slower training and larger networks\n",
        "MAX_MESSAGE_LEN = 30  \n",
        "# Embedding size for words - gives a trade off between expressivity of words and network size\n",
        "EMBEDDING_SIZE = 100\n",
        "# Embedding size for whole messages, same trade off as word embeddings\n",
        "CONTEXT_SIZE = 100\n",
        "# Larger batch sizes generally reach the average response faster, but small batch sizes are\n",
        "# required for the model to learn nuanced responses.  Also, GPU memory limits max batch size.\n",
        "BATCH_SIZE = 4\n",
        "# Helps regularize network and prevent overfitting.\n",
        "DROPOUT = 0.2\n",
        "# High learning rate helps model reach average response faster, but can make it hard to \n",
        "# converge on nuanced responses\n",
        "LEARNING_RATE=0.005\n",
        "\n",
        "# Tokens needed for seq2seq\n",
        "UNK = 0  # words that aren't found in the vocab\n",
        "PAD = 1  # after message has finished, this fills all remaining vector positions\n",
        "START = 2  # provided to the model at position 0 for every response predicted\n",
        "\n",
        "# Implementaiton detail for allowing this to be run in Kaggle's notebook hardware\n",
        "SUB_BATCH_SIZE = 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLpH46tdUXnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets = pd.read_csv('twcs/twcs.csv',encoding='utf-8')\n",
        "print(tweets.shape)\n",
        "tweets.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw48lkL8vm1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7o9B2fj-ttk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def missingData(data):\n",
        "    '''\n",
        "    @author steno\n",
        "    Check the missing data in the features.\n",
        "    This function returns  dataframe with the missing values.\n",
        "    '''\n",
        "    total = data.isnull().sum().sort_values(ascending = False)\n",
        "    percent = (data.isnull().sum()/data.isnull().count()*100).sort_values(ascending = False)\n",
        "    md = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "    md = md[md[\"Percent\"] > 0]\n",
        "    sns.set(style = 'darkgrid')\n",
        "    plt.figure(figsize = (8, 4))\n",
        "    plt.xticks(rotation='90')\n",
        "    sns.barplot(md.index, md[\"Percent\"],color=\"g\",alpha=0.8)\n",
        "    plt.xlabel('Features', fontsize=15)\n",
        "    plt.ylabel('Percent of missing values', fontsize=15)\n",
        "    plt.title('Percent missing data by feature', fontsize=15)\n",
        "    return md"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JdTcoWz-v9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missingData(tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujD7sMqVZgP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_inbound = tweets[pd.isnull(tweets.in_response_to_tweet_id) & tweets.inbound]\n",
        "\n",
        "QnR = pd.merge(first_inbound, tweets, left_on='tweet_id', \n",
        "                                  right_on='in_response_to_tweet_id')\n",
        "\n",
        "# Filter to only outbound replies (from companies)\n",
        "QnR = QnR[QnR.inbound_y ^ True]\n",
        "print(f'Data shape: {QnR.shape}')\n",
        "QnR.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFMPeU2Z_WfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missingData(QnR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou1srZZFaCEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# removing anonymized screen names \n",
        "def sn_replace(match):\n",
        "    _sn = match.group(2).lower()\n",
        "    if not _sn.isnumeric():\n",
        "        # This is a company screen name\n",
        "        return match.group(1) + match.group(2)\n",
        "    return ''\n",
        "\n",
        "sn_re = re.compile('(\\W@|^@)([a-zA-Z0-9_]+)')\n",
        "print(\"Removing anonymized screen names in X...\")\n",
        "QnR[\"text_x\"] = QnR.text_x.progress_apply(lambda txt: sn_re.sub(sn_replace, txt))\n",
        "print(\"Removing anonymized screen names in Y...\")\n",
        "QnR[\"text_y\"] = QnR.text_y.progress_apply(lambda txt: sn_re.sub(sn_replace, txt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWt0dEHYaJk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#making sure the dataframe contains only the needed columns\n",
        "QnR = QnR[[\"tweet_id_x\", \"author_id_x\",\"created_at_x\",\"text_x\",\"author_id_y\",\"created_at_y\",\"text_y\"]]\n",
        "QnR.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSQBaCAc_rsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "QnR.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK71FCH3aPyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = QnR.groupby(\"author_id_y\")[\"text_x\"].count()\n",
        "c = count[count>15000].plot(kind='barh',figsize=(10, 8), color='#619CFF', zorder=2, width=width,)\n",
        "c.set_ylabel('')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScMv4_q-_gD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20, 10))\n",
        "sns.set_style('white')\n",
        "sns.countplot(x='author_id_y', data=QnR)\n",
        "plt.xticks(rotation = 90)\n",
        "plt.title(\"Distributions of Number of Companies' Replies \", fontsize = 20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IczObcv2IE81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "author_grouped = QnR.groupby('author_id_y')\n",
        "top_support_providers = set(author_grouped.agg('count').sort_values(['tweet_id_x'], ascending=[0]).index[:20].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbitV1rOH5F1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "QnR.loc[QnR.author_id_y.isin(top_support_providers)].groupby('author_id_y').tweet_id_x.count().sort_values().plot(kind='barh', title='Top 20 Brands by Volume')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2LVYHadP-TY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "def sentiment_for(text: str) -> float:\n",
        "    return sentiment_analyzer.polarity_scores(text)['compound']\n",
        "QnR['inbound_sentiment'] = QnR.text_x.progress_apply(sentiment_for)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAAjWONMXDic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "QnR \\\n",
        "    .loc[QnR.author_id_y.isin(top_support_providers)] \\\n",
        "    .groupby('author_id_y') \\\n",
        "    .inbound_sentiment.mean() \\\n",
        "    .sort_values() \\\n",
        "    .plot(kind='barh', title='Customer Sentiment by Brand (top 20 by volume)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QYsqvjNJB3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "QnR['created_at_x'] = pd.to_datetime(QnR.created_at_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAJHsXZHJLix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "apple_tweets = QnR \\\n",
        "    .loc[QnR.author_id_y == 'AppleSupport']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8Pld_TnJTBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.subplot(2, 1, 1)\n",
        "\n",
        "ax = apple_tweets \\\n",
        "    .groupby(pd.Grouper(key='created_at_x', freq='24h')) \\\n",
        "    .count() \\\n",
        "    .tweet_id_x.sort_index() \\\n",
        "    .plot(title='@AppleSupport Volume & Sentiment - Impact of the iPhone X', kind='area')\n",
        "ax.set_ylabel('Inbound Tweets')\n",
        "    \n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "ax = apple_tweets \\\n",
        "    .groupby(pd.Grouper(key='created_at_x', freq='24h')) \\\n",
        "    .inbound_sentiment.mean() \\\n",
        "    .sort_index() \\\n",
        "    .plot(color='red')\n",
        "ax.set_ylabel('Customer Sentiment')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCbcnjqQaS6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "amazonQnR = QnR[QnR[\"author_id_y\"]==\"AmazonHelp\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7o5FLElaVY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "amazonQnR.tail(10)[\"text_x\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2YHGiq8aYai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# amazonQnR[\"text_x\"] = amazonQnR[\"text_x\"].str.encode(\"utf-8\")\n",
        "# amazonQnR[\"text_x\"] = amazonQnR[\"text_x\"].apply(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSNtNLhLadgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp_cld = spacy.load('en',disable_pipes=[\"tagger\",\"ner\"])\n",
        "language_detector = spacy_cld.LanguageDetector()\n",
        "nlp_cld.add_pipe(language_detector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpi8dBCxamXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp_cld(amazonQnR.iloc[4][\"text_x\"])\n",
        "print(doc)\n",
        "print(doc._.languages)  \n",
        "print(doc._.language_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5Br7UStapWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask = []\n",
        "try:\n",
        "    for i,doc in tqdm(enumerate(nlp_cld.pipe(amazonQnR[\"text_x\"], batch_size=512))):\n",
        "            if 'en' not in doc._.languages or len(doc._.languages) != 1:\n",
        "                mask.append(False)\n",
        "            else:\n",
        "                mask.append(True)\n",
        "except Exception:\n",
        "    print(\"excepted \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOvSHuJXaxLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "amazonQnR = amazonQnR[mask]\n",
        "# sample a random fraction to visually ensure that we have only English tweets\n",
        "amazonQnR.sample(frac=0.0002)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wrJ9ybgcn6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "amazonQnR.tail(10)[\"text_x\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E9WkDsHc8li",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python -m spacy download en_core_web_lg\n",
        "!python -m spacy link en_core_web_lg en --force"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftSIL2FFcsgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load(\"en\",disable_pipes=[\"tagger\"])\n",
        "\n",
        "from spacymoji import Emoji\n",
        "emoji = Emoji(nlp)\n",
        "nlp.add_pipe(emoji, first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT6trutpcurz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(nlp.pipe_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxBTVGORedHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emojis = []\n",
        "for doc in tqdm(nlp.pipe(amazonQnR[\"text_x\"], batch_size=512)):\n",
        "    if doc._.has_emoji:\n",
        "        for e in doc._.emoji:\n",
        "            emojis.extend(e[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsRoIRbaeiDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eCount = Counter(emojis)\n",
        "eCount.most_common(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKfg4ddAgUuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response_emojis = []\n",
        "for doc in tqdm(nlp.pipe(amazonQnR[\"text_y\"], batch_size=512)):\n",
        "    elist = []\n",
        "    if doc._.has_emoji:\n",
        "        for e in doc._.emoji:\n",
        "            elist.append(e[0])\n",
        "    response_emojis.append(elist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t7w7h4Qgf7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Counter([item for sublist in response_emojis for item in sublist]).most_common(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhGhn0BEgiqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "sent_analyser = SentimentIntensityAnalyzer()\n",
        "positive_text = \"love this phone! its the best one I've owned over the years\"\n",
        "negative_text = \"what sort of company makes such products? this phone hangs up all the time and is totally useless\"\n",
        "print(\"positive_text sentiment : \",sent_analyser.polarity_scores(positive_text)[\"compound\"])\n",
        "print(\"negative_text sentiment : \",sent_analyser.polarity_scores(negative_text)[\"compound\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpjJdy9_gm3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentiment(text):\n",
        "    return (sent_analyser.polarity_scores(text)[\"compound\"] + TextBlob(text).sentiment.polarity)/2\n",
        "amazonQnR[\"text_x_sentiment\"] = amazonQnR[\"text_x\"].apply(sentiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xdhzar8gqRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response_emojis_for_positive_queries = []\n",
        "response_emojis_for_negative_queries = []\n",
        "for i,sentiment in enumerate(amazonQnR[\"text_x_sentiment\"]):\n",
        "    if sentiment > 0.0:\n",
        "        response_emojis_for_positive_queries.extend(response_emojis[i])\n",
        "    elif sentiment < 0.0:\n",
        "        response_emojis_for_negative_queries.extend(response_emojis[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvazEQ_2gsmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "amazonQnR[amazonQnR[\"text_x_sentiment\"]>0].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzxER0edguoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Counter(response_emojis_for_positive_queries).most_common(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eylqbytygwjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Counter(response_emojis_for_negative_queries).most_common(10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpdSrv_GgyU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = QnR.groupby(\"author_id_y\")[\"text_x\"].count()\n",
        "c = count[count>15000].plot(kind='barh',figsize=(10, 8), color='#619CFF', zorder=2, width=width,)\n",
        "c.set_ylabel('')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FD0Oib1g05s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "airlinesQnR = QnR[(QnR[\"author_id_y\"]==\"AmericanAir\")|(QnR[\"author_id_y\"]==\"British_Airways\")]\n",
        "airlinesQnR.head(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIHfVr8Kg3SV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "airlinesQnR[\"text_y\"] = airlinesQnR[\"text_y\"].str.lower()  \n",
        "stop = stopwords.words('english')\n",
        "big_regex = re.compile(' | '.join(stop))\n",
        "airlinesQnR[\"text_y\"].progress_apply(lambda x: big_regex.sub(\" \",x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoMTDv5og6Pc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scattertext as st\n",
        "nlp = spacy.load('en',disable_pipes=[\"tagger\",\"ner\"])\n",
        "airlinesQnR['parsed'] = airlinesQnR.text_y.progress_apply(nlp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBcpfxg5g9G0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = st.CorpusFromParsedDocuments(airlinesQnR,\n",
        "                             category_col='author_id_y',\n",
        "                             parsed_col='parsed').build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62huAyEBg_Mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "html = st.produce_scattertext_explorer(corpus,\n",
        "          category='British_Airways',\n",
        "          category_name='British Airways',\n",
        "          not_category_name='American Airlines',\n",
        "          width_in_pixels=600,\n",
        "          minimum_term_frequency=10,\n",
        "          term_significance = st.LogOddsRatioUninformativeDirichletPrior(),\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otyKeCcxhBZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"americanAir-vs-britishAirways.html\"\n",
        "open(filename, 'wb').write(html.encode('utf-8'))\n",
        "IFrame(src=filename, width = 800, height=700)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptp_P_rVhFsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feat_builder = st.FeatsFromOnlyEmpath()\n",
        "empath_corpus = st.CorpusFromParsedDocuments(airlinesQnR,\n",
        "                                              category_col='author_id_y',\n",
        "                                              feats_from_spacy_doc=feat_builder,\n",
        "                                              parsed_col='parsed').build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puP_YutEhJ9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "html = st.produce_scattertext_explorer(empath_corpus,\n",
        "                                        category='British_Airways',\n",
        "                                        category_name='British Airways',\n",
        "                                        not_category_name='American Airlines',\n",
        "                                        width_in_pixels=700,\n",
        "                                        metadata=airlinesQnR['author_id_y'],\n",
        "                                        use_non_text_features=True,\n",
        "                                        use_full_doc=True,\n",
        "                                        topic_model_term_lists=feat_builder.get_top_model_term_lists())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4trjUJ5hM58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"empath-BA-vs-AA.html\"\n",
        "open(filename, 'wb').write(html.encode('utf-8'))\n",
        "IFrame(src=filename, width = 900, height=700)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS9a4TxphQu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = (st.CorpusFromParsedDocuments(airlinesQnR,\n",
        "                             category_col='author_id_y',\n",
        "                             parsed_col='parsed').build().get_stoplisted_unigram_corpus())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dldyTqMGhVNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_term = 'delay'\n",
        "html = st.word_similarity_explorer(corpus,\n",
        "                                   category='British_Airways',\n",
        "                                   category_name='British Airways',\n",
        "                                   not_category_name='American Airlines',\n",
        "                                   target_term=target_term,\n",
        "                                   minimum_term_frequency=5,\n",
        "                                   width_in_pixels=800)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpVB3HmWhXJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = 'similarity.html'\n",
        "open(file_name, 'wb').write(html.encode('utf-8'))\n",
        "IFrame(src=file_name, width = 1000, height=700)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNTbw8dxhbdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "html = st.produce_projection_explorer(corpus,\n",
        "                                   category='British_Airways',\n",
        "                                   category_name='British Airways',\n",
        "                                   not_category_name='American Airlines',\n",
        "                                   width_in_pixels=800)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPgBgt_ZAoaA",
        "colab_type": "text"
      },
      "source": [
        "**Lower case**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr5J9NC8hq3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_uppercase(text):\n",
        "    text_lowercase = ' '.join(x.lower() for x in text.split())# It will discard all uppercases\n",
        "    return text_lowercase"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9Ezb9ZbATIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "QnR['text_x_clean'] = QnR['text_x'].apply(lambda x: remove_uppercase(x))\n",
        "QnR['text_y_clean'] = QnR['text_y'].apply(lambda x: remove_uppercase(x))\n",
        "#in modo da poter rimuovere i nomi delle compagnie\n",
        "QnR['author_id_y'] = QnR['author_id_y'].apply(lambda x: remove_uppercase(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfBiEWuYAuQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "QnR.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79kCqb0OA2My",
        "colab_type": "text"
      },
      "source": [
        "**Remove Puntuaction**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGPHsXRRAyID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "string.punctuation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8BTqU6bAyTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punct(text):\n",
        "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])# It will discard all punctuations\n",
        "    return text_nopunct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OMj_fCLAyWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "QnR['text_x_clean'] = QnR['text_x_clean'].apply(lambda x: remove_punct(x))\n",
        "QnR['text_y_clean'] = QnR['text_y_clean'].apply(lambda x: remove_punct(x))\n",
        "QnR.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duj9QgxXBKn7",
        "colab_type": "text"
      },
      "source": [
        "**Removing usernames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y9StbmZAzOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# usernames = QnR['author_id_x'].unique()\n",
        "companies = QnR['author_id_y'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6ehBFMoAzKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gli username dei clienti sono numeri\n",
        "QnR['text_x_clean'] = QnR['text_x_clean'].str.replace('\\d+', '')\n",
        "QnR['text_y_clean'] = QnR['text_y_clean'].str.replace('\\d+', '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vaWQL9fAzH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "QnR['text_x_clean'] = QnR['text_x_clean'].str.replace('|'.join(companies), '')\n",
        "QnR['text_y_clean'] = QnR['text_y_clean'].str.replace('|'.join(companies), '')\n",
        "QnR.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26zPIow4Bj6G",
        "colab_type": "text"
      },
      "source": [
        "**Checking Most Common Words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPSDubO9AzFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freqX = pd.Series(' '.join(QnR['text_x_clean']).split()).value_counts()[:10]\n",
        "freqY = pd.Series(' '.join(QnR['text_y_clean']).split()).value_counts()[:10]\n",
        "print('FREQ X: \\n',freqX,'\\nFREQ Y: \\n', freqY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZecRZ3Z3AzCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#removing them\n",
        "freqX = list(freqX.index)\n",
        "freqY = list(freqY.index)\n",
        "QnR['text_x_clean'] = QnR['text_x_clean'].apply(lambda x: \" \".join(x for x in x.split() if x not in freqX))\n",
        "QnR['text_y_clean'] = QnR['text_y_clean'].apply(lambda x: \" \".join(x for x in x.split() if x not in freqY))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmE3NbtHB3T0",
        "colab_type": "text"
      },
      "source": [
        "**Checking Most Rare Words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbK8QW9fAy_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rareX = pd.Series(' '.join(QnR['text_x_clean']).split()).value_counts()[-100:]\n",
        "rareY = pd.Series(' '.join(QnR['text_y_clean']).split()).value_counts()[-100:]\n",
        "print('RARE X: \\n',rareX,'\\nRARE Y: \\n', rareY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3kM4ouQAy9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#removing them\n",
        "rareX = list(rareX.index)\n",
        "rareY = list(rareY.index)\n",
        "QnR['text_x_clean'] = QnR['text_x_clean'].apply(lambda x: \" \".join(x for x in x.split() if x not in rareX))\n",
        "QnR['text_y_clean'] = QnR['text_y_clean'].apply(lambda x: \" \".join(x for x in x.split() if x not in rareY))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0chf5A1HCGGw",
        "colab_type": "text"
      },
      "source": [
        "**Tokenizing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIX-lViKAy6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "# Function to Tokenize words\n",
        "def tokenize(text):\n",
        "    tokens = re.split('\\W+', text) #W+ means that either a word character (A-Za-z0-9_) or a dash (-) can go there.\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE8z1CpYAy4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "QnR['text_x_tokenized'] = QnR['text_x_clean'].apply(lambda x: tokenize(x.lower())) \n",
        "QnR['text_y_tokenized'] = QnR['text_y_clean'].apply(lambda x: tokenize(x.lower()))\n",
        "#We convert to lower as Python is case-sensitive.\n",
        "QnR.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rzJ97ZxCdbk",
        "colab_type": "text"
      },
      "source": [
        "**Remove StopWords**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PK775VLAy1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "\n",
        "stopword = nltk.corpus.stopwords.words('english') # All English Stopwords\n",
        "\n",
        "# Function to remove Stopwords\n",
        "def remove_stopwords(tokenized_list):\n",
        "    text = [word for word in tokenized_list if word not in stopword]# To remove all stopwords\n",
        "    return text\n",
        "\n",
        "QnR['text_x_tokenized'] = QnR['text_x_tokenized'].apply(lambda x: remove_stopwords(x))\n",
        "QnR['text_y_tokenized'] = QnR['text_y_tokenized'].apply(lambda x: remove_stopwords(x))\n",
        "QnR.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv0E8wolCqyd",
        "colab_type": "text"
      },
      "source": [
        "**Lemmatizing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHs0mSIvAyzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('wordnet')\n",
        "wn = nltk.WordNetLemmatizer()\n",
        "\n",
        "def lemmatizing(tokenized_text):\n",
        "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61pcafQUAywj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "QnR['text_x_lemmatized'] = QnR['text_x_tokenized'].apply(lambda x: lemmatizing(x))\n",
        "QnR['text_y_lemmatized'] = QnR['text_y_tokenized'].apply(lambda x: lemmatizing(x))\n",
        "QnR.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aO-QPAaC5Em",
        "colab_type": "text"
      },
      "source": [
        "**Count Vectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwjAHf6NC22L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Load the library with the CountVectorizer method\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV_W2_ceAyuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "questions = QnR['text_x_clean'].dropna()\n",
        "q = np.array(questions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5OaKcOEAyrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "countV = CountVectorizer(stop_words='english',\n",
        "                         max_features=10000)\n",
        "\n",
        "# Fit and transform the processed titles\n",
        "bagQuestions = countV.fit_transform(q)\n",
        "\n",
        "print('BOW Questions: ',bagQuestions.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAjcEGgWAyoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = countV.get_feature_names()\n",
        "total_counts = np.zeros(len(words))\n",
        "for t in bagQuestions:\n",
        "    total_counts += t.toarray()[0]\n",
        "    \n",
        "count_dict = (zip(words, total_counts))\n",
        "count_dict = sorted(count_dict, key=lambda x:x[1], reverse=True)\n",
        "d = dict(count_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcNouZVRAyl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "sns.set_style('white')\n",
        "plt.figure(figsize=(15,15))\n",
        "wc = WordCloud(background_color=\"white\",width=1000,height=1000, max_words=50,\n",
        "               relative_scaling=0.5,normalize_plurals=False).generate_from_frequencies(d)\n",
        "plt.title('WordCloud')\n",
        "plt.imshow(wc)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rgHQ38pDdvw",
        "colab_type": "text"
      },
      "source": [
        "## **Seq2Seq  MODEL DEVELOPMENT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9eg0gghAyjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import casual_tokenize\n",
        "count_vec = CountVectorizer(tokenizer=casual_tokenize, max_features=MAX_VOCAB_SIZE - 3)\n",
        "print(\"Fitting CountVectorizer on X and Y text data...\")\n",
        "count_vec.fit(tqdm(QnR[\"text_x\"] + QnR[\"text_y\"]))\n",
        "analyzer = count_vec.build_analyzer()\n",
        "vocab = {k: v + 3 for k, v in count_vec.vocabulary_.items()}\n",
        "vocab['__unk__'] = UNK\n",
        "vocab['__pad__'] = PAD\n",
        "vocab['__start__'] = START\n",
        "# Used to turn seq2seq predictions into human readable strings\n",
        "reverse_vocab = {v: k for k, v in vocab.items()}\n",
        "print(f\"Learned vocab of {len(vocab)} items.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfUEP9uiAyg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_word_idx(sentence):\n",
        "    full_length = [vocab.get(tok, UNK) for tok in analyzer(sentence)] + [PAD] * MAX_MESSAGE_LEN\n",
        "    return full_length[:MAX_MESSAGE_LEN]\n",
        "\n",
        "def from_word_idx(word_idxs):\n",
        "    return ' '.join(reverse_vocab[idx] for idx in word_idxs if idx != PAD).strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEqsZ6YzAyeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make sure our helpers work as expected...\n",
        "QnR[\"text_x\"].head().apply(to_word_idx).apply(from_word_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsDkeymPAya_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Calculating word indexes for X...\")\n",
        "x = pd.np.vstack(QnR[\"text_x\"].progress_apply(to_word_idx).values)\n",
        "print(\"Calculating word indexes for Y...\")\n",
        "y = pd.np.vstack(QnR[\"text_y\"].progress_apply(to_word_idx).values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwL4GUI7E22I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_idx = list(range(len(x)))\n",
        "train_idx = set(random.sample(all_idx, int(0.8 * len(all_idx))))\n",
        "test_idx = {idx for idx in all_idx if idx not in train_idx}\n",
        "\n",
        "train_x = x[list(train_idx)]\n",
        "test_x = x[list(test_idx)]\n",
        "train_y = y[list(train_idx)]\n",
        "test_y = y[list(test_idx)]\n",
        "\n",
        "assert train_x.shape == train_y.shape\n",
        "assert test_x.shape == test_y.shape\n",
        "\n",
        "print(f'Training data of shape {train_x.shape} and test data of shape {test_x.shape}.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5eFseVtE2uL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dense, Input, LSTM, Dropout, Embedding, RepeatVector, concatenate, TimeDistributed\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4Ys7dhJE2nE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "    shared_embedding = Embedding(\n",
        "        output_dim=EMBEDDING_SIZE,\n",
        "        input_dim=MAX_VOCAB_SIZE,\n",
        "        input_length=MAX_MESSAGE_LEN,\n",
        "        name='embedding',\n",
        "    )\n",
        "    \n",
        "    # ENCODER\n",
        "    \n",
        "    encoder_input = Input(\n",
        "        shape=(MAX_MESSAGE_LEN,),\n",
        "        dtype='int32',\n",
        "        name='encoder_input',\n",
        "    )\n",
        "    \n",
        "    embedded_input = shared_embedding(encoder_input)\n",
        "    \n",
        "    # No return_sequences - since the encoder here only produces a single value for the\n",
        "    # input sequence provided.\n",
        "    encoder_rnn = LSTM(\n",
        "        CONTEXT_SIZE,\n",
        "        name='encoder',\n",
        "        dropout=DROPOUT\n",
        "    )\n",
        "    \n",
        "    context = RepeatVector(MAX_MESSAGE_LEN)(encoder_rnn(embedded_input))\n",
        "    \n",
        "    # DECODER\n",
        "    \n",
        "    last_word_input = Input(\n",
        "        shape=(MAX_MESSAGE_LEN, ),\n",
        "        dtype='int32',\n",
        "        name='last_word_input',\n",
        "    )\n",
        "    \n",
        "    embedded_last_word = shared_embedding(last_word_input)\n",
        "    # Combines the context produced by the encoder and the last word uttered as inputs\n",
        "    # to the decoder.\n",
        "    decoder_input = concatenate([embedded_last_word, context], axis=2)\n",
        "    \n",
        "    # return_sequences causes LSTM to produce one output per timestep instead of one at the\n",
        "    # end of the intput, which is important for sequence producing models.\n",
        "    decoder_rnn = LSTM(\n",
        "        CONTEXT_SIZE,\n",
        "        name='decoder',\n",
        "        return_sequences=True,\n",
        "        dropout=DROPOUT\n",
        "    )\n",
        "    \n",
        "    decoder_output = decoder_rnn(decoder_input)\n",
        "    \n",
        "    # TimeDistributed allows the dense layer to be applied to each decoder output per timestep\n",
        "    next_word_dense = TimeDistributed(\n",
        "        Dense(int(MAX_VOCAB_SIZE / 2), activation='relu'),\n",
        "        name='next_word_dense',\n",
        "    )(decoder_output)\n",
        "    \n",
        "    next_word = TimeDistributed(\n",
        "        Dense(MAX_VOCAB_SIZE, activation='softmax'),\n",
        "        name='next_word_softmax'\n",
        "    )(next_word_dense)\n",
        "    \n",
        "    return Model(inputs=[encoder_input, last_word_input], outputs=[next_word])\n",
        "\n",
        "s2s_model = create_model()\n",
        "optimizer = Adam(lr=LEARNING_RATE, clipvalue=5.0)\n",
        "s2s_model.compile(optimizer='adam', loss='categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNH4qm-4E2i2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_start_token(y_array):\n",
        "    \"\"\" Adds the start token to vectors.  Used for training data. \"\"\"\n",
        "    return np.hstack([\n",
        "        START * np.ones((len(y_array), 1)),\n",
        "        y_array[:, :-1],\n",
        "    ])\n",
        "\n",
        "def binarize_labels(labels):\n",
        "    \"\"\" Helper function that turns integer word indexes into sparse binary matrices for \n",
        "        the expected model output.\n",
        "    \"\"\"\n",
        "    return np.array([np_utils.to_categorical(row, num_classes=MAX_VOCAB_SIZE)\n",
        "                     for row in labels])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GycA3bW1E2e1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def respond_to(model, text):\n",
        "    \"\"\" Helper function that takes a text input and provides a text output. \"\"\"\n",
        "    input_y = add_start_token(PAD * np.ones((1, MAX_MESSAGE_LEN)))\n",
        "    idxs = np.array(to_word_idx(text)).reshape((1, MAX_MESSAGE_LEN))\n",
        "    for position in range(MAX_MESSAGE_LEN - 1):\n",
        "        prediction = model.predict([idxs, input_y]).argmax(axis=2)[0]\n",
        "        input_y[:,position + 1] = prediction[position]\n",
        "    return from_word_idx(model.predict([idxs, input_y]).argmax(axis=2)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB7tF_SlE2aR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_mini_epoch(model, start_idx, end_idx):\n",
        "    \"\"\" Batching seems necessary in Kaggle Jupyter Notebook environments, since\n",
        "        `model.fit` seems to freeze on larger batches (somewhere 1k-10k).\n",
        "    \"\"\"\n",
        "    b_train_y = binarize_labels(train_y[start_idx:end_idx])\n",
        "    input_train_y = add_start_token(train_y[start_idx:end_idx])\n",
        "    \n",
        "    model.fit(\n",
        "        [train_x[start_idx:end_idx], input_train_y], \n",
        "        b_train_y,\n",
        "        epochs=1,\n",
        "        batch_size=BATCH_SIZE,\n",
        "    )\n",
        "    \n",
        "    rand_idx = random.sample(list(range(len(test_x))), SUB_BATCH_SIZE)\n",
        "    print('Test results:', model.evaluate(\n",
        "        [test_x[rand_idx], add_start_token(test_y[rand_idx])],\n",
        "        binarize_labels(test_y[rand_idx])\n",
        "    ))\n",
        "    \n",
        "    input_strings = [\n",
        "        \"@AppleSupport I fix I this I stupid I problem I\",\n",
        "        \"@AmazonHelp I hadnt expected that such a big brand like amazon would have such a poor customer service.\",\n",
        "    ]\n",
        "    \n",
        "    for input_string in input_strings:\n",
        "        output_string = respond_to(model, input_string)\n",
        "        print(f'> \"{input_string}\"\\n< \"{output_string}\"')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4tw41ABFap8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_time_limit = 360 * 60  # seconds (notebooks terminate after 1 hour)\n",
        "start_time = time.time()\n",
        "stop_after = start_time + training_time_limit\n",
        "\n",
        "class TimesUpInterrupt(Exception):\n",
        "    pass\n",
        "\n",
        "try:\n",
        "    for epoch in range(100):\n",
        "        print(f'Training in epoch {epoch}...')\n",
        "        for start_idx in range(0, len(train_x), SUB_BATCH_SIZE):\n",
        "            train_mini_epoch(s2s_model, start_idx, start_idx + SUB_BATCH_SIZE)\n",
        "            if time.time() > stop_after:\n",
        "                raise TimesUpInterrupt\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Halting training from keyboard interrupt.\")\n",
        "except TimesUpInterrupt:\n",
        "    print(f\"Halting after {time.time() - start_time} seconds spent training.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pgb6Lx1FalY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "respond_to(s2s_model, '''@AppleSupport iPhone 8 touchID doesnt unlock while charging on \n",
        "    110v w/ 61w laptop charger to usbc lightning cable just uh.. so you guys know''')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTMdjwl2Fagc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "respond_to(s2s_model, '''@sprintcare I can't make calls... wtf''')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V56GMqEuAyYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}